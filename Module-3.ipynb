{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe8d766a-033a-4e8a-a42a-5d401f069f39",
   "metadata": {},
   "source": [
    "# Thread level Persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61ece93-fce1-4179-b3cf-f8c6bda9cc82",
   "metadata": {},
   "source": [
    "#### **1. Checkpointers (in LangGraph)**\n",
    "\n",
    "* Think of a **checkpointer** like a “save game” in a video game.\n",
    "* It **remembers the state** of your workflow (like what data you’ve processed, what step you’re on).\n",
    "* If something crashes or you want to resume later, the checkpointer lets you **continue from where you left off** instead of starting from scratch.\n",
    "\n",
    "Example:\n",
    "You’re processing 100 documents. After 50, your program stops.\n",
    "\n",
    "* With a checkpointer → next time, it resumes at document 51.\n",
    "* Without a checkpointer → it starts again from document 1.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Threads (in LangGraph)**\n",
    "\n",
    "* A **thread** is like a “conversation line” or “execution flow.”\n",
    "* Each user session or workflow run can have its own **thread ID**.\n",
    "* This keeps data and context separate between different tasks or users.\n",
    "\n",
    "Example:\n",
    "\n",
    "* User A’s chatbot session = Thread 1\n",
    "* User B’s chatbot session = Thread 2\n",
    "* They don’t mix, because each thread has its own memory and checkpoints.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. State Snapshot**\n",
    "\n",
    "* A **snapshot** is like taking a photo of your program’s current state.\n",
    "* It freezes everything (inputs, outputs, progress) so you can **restore it later**.\n",
    "* Snapshots are created by checkpointers to know exactly where to restart.\n",
    "\n",
    "Example: Chatbot saves a snapshot after every reply. If it crashes, it reloads the last snapshot and continues.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Short-term Memory**\n",
    "\n",
    "* Short-term memory = what the system remembers **within a single thread/session**.\n",
    "* It’s like remembering the last few messages, but it doesn’t survive forever.\n",
    "\n",
    "Example: The chatbot remembers what you said 2 minutes ago in the same session.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Long-term Memory**\n",
    "\n",
    "* Long-term memory = what’s saved **permanently across sessions/threads**.\n",
    "* It survives restarts and can be recalled even in a new conversation.\n",
    "\n",
    "Example: The chatbot remembers your name and preferences even if you come back tomorrow.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2de003-2093-4607-ae00-8c1551073bbd",
   "metadata": {},
   "source": [
    "# Short-term memory with the InMemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5163238-a891-4157-952c-a658f8d967bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage, RemoveMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e235a3-f23e-4b24-a699-8d3956b46078",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=config.gemini_api_key,\n",
    "    temperature=0,\n",
    "    max_tokens=250,\n",
    "    model_kwargs={\"seed\": 42}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe1a6233-3ef7-47d1-8821-4480f000b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AskGeminiAI(question):\n",
    "    response = llm.invoke(question)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b81df8-8598-44a2-85c2-e81325954cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba3f17f8-3916-4572-8d28-f085b0f9542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(state: State) -> State:\n",
    "    \n",
    "    print(f\"\\n-------> ENTERING ask_question:\")\n",
    "    \n",
    "    question = \"What is your question?\"\n",
    "    print(question)\n",
    "    \n",
    "    return State(messages = [AIMessage(question), HumanMessage(input())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f718052-ea57-46d8-bc12-988164479e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State) -> State:\n",
    "    \n",
    "    print(f\"\\n-------> ENTERING chatbot:\")\n",
    "        \n",
    "    system_message = f'''\n",
    "    Here's a quick summary of what's been discussed so far:\n",
    "    {state.get(\"summary\", \"\")}\n",
    "    \n",
    "    Keep this in mind as you answer the next question.\n",
    "    '''\n",
    "    \n",
    "    response = AskGeminiAI([SystemMessage(system_message)] + state[\"messages\"])\n",
    "    response.pretty_print()\n",
    "    \n",
    "    return State(messages = [response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1bd4387-ca86-4eeb-be40-86fbe8c413d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_messages(state: State) -> State:\n",
    "    print(f\"\\n-------> ENTERING summarize_messages:\")\n",
    "\n",
    "    new_conversation = \"\"\n",
    "    for i in state[\"messages\"]:\n",
    "        new_conversation += f\"{i.type}: {i.content}\\n\\n\"\n",
    "    \n",
    "    summary_instructions = f'''\n",
    "        Update the ongoing summary by incorporating the new lines of conversation below. \n",
    "        Build upon the previous summary rather than repeating it, \n",
    "        so that the result reflects the most recent context and developments.\n",
    "        Respond only with the summary.\n",
    "        \n",
    "        Previous Summary:\n",
    "        {state.get(\"summary\", \"\")}\n",
    "        \n",
    "        New Conversation:\n",
    "        {new_conversation}\n",
    "        '''\n",
    "\n",
    "    print(summary_instructions)\n",
    "\n",
    "    summary = AskGeminiAI([HumanMessage(summary_instructions)])\n",
    "    \n",
    "    remove_messages = [RemoveMessage(id = i.id) for i in state[\"messages\"][:]]\n",
    "\n",
    "    return State(messages = remove_messages, summary = summary.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e7723a5-6253-43ec-878a-aca55b817f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1ea1e527190>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_node(\"ask_question\", ask_question)\n",
    "graph.add_node(\"chatbot\", chatbot)\n",
    "graph.add_node(\"summarize_messages\", summarize_messages)\n",
    "\n",
    "graph.add_edge(START, \"ask_question\")\n",
    "graph.add_edge(\"ask_question\", \"chatbot\")\n",
    "graph.add_edge(\"chatbot\", \"summarize_messages\")\n",
    "graph.add_edge(\"summarize_messages\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad6ea384-db25-4114-864e-59eb1a9f9c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver()\n",
    "graph_compiled = graph.compile(checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83c22b1e-88e0-4673-ae11-830bffa0d8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-----------+      \n",
      "    | __start__ |      \n",
      "    +-----------+      \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      "   +--------------+    \n",
      "   | ask_question |    \n",
      "   +--------------+    \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      "      +---------+      \n",
      "      | chatbot |      \n",
      "      +---------+      \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      "+--------------------+ \n",
      "| summarize_messages | \n",
      "+--------------------+ \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      "      +---------+      \n",
      "      | __end__ |      \n",
      "      +---------+      \n"
     ]
    }
   ],
   "source": [
    "print(graph_compiled.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a19bb142-b643-4db5-84a5-b2e810150a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "config2 = {\"configurable\": {\"thread_id\": \"2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c61b08d-d24d-4418-b831-ad85d136c901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------> ENTERING ask_question:\n",
      "What is your question?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Who is Ash Ketchum?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------> ENTERING chatbot:\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ash Ketchum is the main protagonist of the *Pokémon* anime series. He's a young boy from Pallet Town who dreams of becoming a Pokémon Master. He travels the world with his Pokémon, most notably Pikachu, battling Gym Leaders, participating in tournaments, and encountering various adventures. After 25 seasons, he finally achieved his goal of becoming a World Champion.\n",
      "\n",
      "-------> ENTERING summarize_messages:\n",
      "\n",
      "        Update the ongoing summary by incorporating the new lines of conversation below. \n",
      "        Build upon the previous summary rather than repeating it, \n",
      "        so that the result reflects the most recent context and developments.\n",
      "        Respond only with the summary.\n",
      "\n",
      "        Previous Summary:\n",
      "        \n",
      "\n",
      "        New Conversation:\n",
      "        ai: What is your question?\n",
      "\n",
      "human: Who is Ash Ketchum?\n",
      "\n",
      "ai: Ash Ketchum is the main protagonist of the *Pokémon* anime series. He's a young boy from Pallet Town who dreams of becoming a Pokémon Master. He travels the world with his Pokémon, most notably Pikachu, battling Gym Leaders, participating in tournaments, and encountering various adventures. After 25 seasons, he finally achieved his goal of becoming a World Champion.\n",
      "\n",
      "\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [],\n",
       " 'summary': \"Ash Ketchum is the main protagonist of the *Pokémon* anime series. He's a young boy from Pallet Town who dreams of becoming a Pokémon Master. He travels the world with his Pokémon, most notably Pikachu, battling Gym Leaders, participating in tournaments, and encountering various adventures. After 25 seasons, he finally achieved his goal of becoming a World Champion. The user inquired about Ash Ketchum, prompting the AI to provide this information.\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_compiled.invoke(State(), config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10080ace-4d3d-4705-a6ee-0577615c16ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llms_course_env)",
   "language": "python",
   "name": "llms_course_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
